{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c531b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4, tiktoken, numpy as np, os\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "learn_api_key = os.environ['LANGCHAIN_API_KEY']\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5de95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03447727486491203, 0.03102317824959755, 0.006734970025718212, 0.026108985766768456, -0.03936202451586723, -0.16030244529247284, 0.06692401319742203, -0.006441489793360233, -0.0474504791200161, 0.014758856035768986, 0.07087527960538864, 0.05552763119339943, 0.019193334504961967, -0.026251312345266342, -0.01010954286903143, -0.02694045566022396, 0.022307461127638817, -0.022226648405194283, -0.14969263970851898, -0.017493007704615593, 0.00767625542357564, 0.05435224249958992, 0.0032543970737606287, 0.031725890934467316, -0.0846213847398758, -0.02940601296722889, 0.05159561336040497, 0.04812406003475189, -0.0033148222137242556, -0.058279167860746384, 0.04196927323937416, 0.022210685536265373, 0.1281888335943222, -0.022338971495628357, -0.011656315997242928, 0.06292839348316193, -0.032876335084438324, -0.09122604131698608, -0.031175347045063972, 0.0526994913816452, 0.04703482985496521, -0.08420311659574509, -0.030056199058890343, -0.02074483036994934, 0.009517835453152657, -0.0037217906210571527, 0.007343285251408815, 0.03932438790798187, 0.0932740643620491, -0.003788596484810114, -0.052742067724466324, -0.05805816128849983, -0.006864361464977264, 0.005283191800117493, 0.0828929990530014, 0.019362755119800568, 0.0062844837084412575, -0.010330787859857082, 0.009032378904521465, -0.037683695554733276, -0.04520607739686966, 0.024016305804252625, -0.006944137159734964, 0.013491630554199219, 0.10005494207143784, -0.07168391346931458, -0.021695120260119438, 0.031618405133485794, -0.051634665578603745, -0.08224772661924362, -0.06569333374500275, -0.00989533495157957, 0.005816374905407429, 0.07355456054210663, -0.034050311893224716, 0.0248861201107502, 0.014488042332231998, 0.02645738422870636, 0.009656722657382488, 0.0302172489464283, 0.05280393362045288, -0.07535984367132187, 0.009897145442664623, 0.029836809262633324, 0.01755557768046856, 0.023091984912753105, 0.001933806692250073, 0.0014002545503899455, -0.04717595875263214, -0.011194315738976002, -0.11420144140720367, -0.019811924546957016, 0.040266189724206924, 0.0021929906215518713, -0.07979220896959305, -0.02538231760263443, 0.09448299556970596, -0.02898104302585125, -0.14500252902507782, 0.23097744584083557, 0.027731187641620636, 0.03211146965622902, 0.03106505796313286, 0.04283284768462181, 0.06423777341842651, 0.03216316178441048, -0.004876770544797182, 0.055699463933706284, -0.03753238171339035, -0.02150554023683071, -0.028342634439468384, -0.028846951201558113, 0.0383530892431736, -0.017468664795160294, 0.052485305815935135, -0.07487601786851883, -0.03125976398587227, 0.021841565147042274, -0.03989570587873459, -0.008587091229856014, 0.026956576853990555, -0.04849553853273392, 0.011469882912933826, 0.02961820363998413, -0.02057218924164772, 0.013103843666613102, 0.028833510354161263, -3.1941990848222185e-33, 0.06478213518857956, -0.018130183219909668, 0.051789961755275726, 0.12198275327682495, 0.028780106455087662, 0.008721951395273209, -0.07052119821310043, -0.016907278448343277, 0.04073973000049591, 0.042116157710552216, 0.025447236374020576, 0.03574628755450249, -0.04914471507072449, 0.0021290204022079706, -0.015546582639217377, 0.050730545073747635, -0.0481853261590004, 0.03588061034679413, -0.0040670474991202354, 0.10172472149133682, -0.05597002059221268, -0.010681048966944218, 0.01123578567057848, 0.09068653732538223, 0.004234451334923506, 0.035138655453920364, -0.009702847339212894, -0.09386517852544785, 0.0928555428981781, 0.008004927076399326, -0.007705425377935171, -0.05208674445748329, -0.012587991543114185, 0.0032669377978891134, 0.006013509817421436, 0.007581559009850025, 0.01051718182861805, -0.08634556829929352, -0.06987880170345306, -0.0025338928680866957, -0.09097658842802048, 0.04688733071088791, 0.052076540887355804, 0.007193844299763441, 0.010903622955083847, -0.0052295587956905365, 0.013937311246991158, 0.021968349814414978, 0.03420866280794144, 0.060224682092666626, 0.00011665470083244145, 0.014731976203620434, -0.07008926570415497, 0.028499048203229904, -0.02760172076523304, 0.010768445208668709, 0.034830961376428604, -0.02248787134885788, 0.009769017808139324, 0.07722785323858261, 0.021588314324617386, 0.11495620757341385, -0.0680011734366417, 0.02376098558306694, -0.0159839428961277, -0.0178269911557436, 0.06439495831727982, 0.032025739550590515, 0.05027025192975998, -0.005913770757615566, -0.03370805084705353, 0.017840256914496422, 0.016573317348957062, 0.06329657882452011, 0.03467721864581108, 0.046473488211631775, 0.09790610522031784, -0.00663550291210413, 0.02520712837576866, -0.07798824459314346, 0.0169264767318964, -0.000945797364693135, 0.022471921518445015, -0.038253191858530045, 0.09570474177598953, -0.005350803025066853, 0.010469110682606697, -0.11524055153131485, -0.013262521475553513, -0.010709455236792564, -0.08311725407838821, 0.07327353954315186, 0.04939225688576698, -0.008994322270154953, -0.09584552049636841, 3.3661485617505796e-33, 0.12493184208869934, 0.01934972032904625, -0.05822571739554405, -0.03598826378583908, -0.05074676498770714, -0.04566238448023796, -0.08260336518287659, 0.1481948047876358, -0.08842118829488754, 0.06027443706989288, 0.05103015899658203, 0.01030314713716507, 0.14121422171592712, 0.03081384487450123, 0.061033159494400024, -0.052851270884275436, 0.1366489678621292, 0.00918989721685648, -0.01732518896460533, -0.012848555110394955, -0.007995282299816608, -0.0509800985455513, -0.05235064774751663, 0.007593012880533934, -0.015166307799518108, 0.01696030981838703, 0.021270520985126495, 0.020558107644319534, -0.12002813816070557, 0.014461833983659744, 0.02675991877913475, 0.025330696254968643, -0.0427546352148056, 0.006768387276679277, -0.01445858459919691, 0.04526195675134659, -0.09147648513317108, -0.019439145922660828, -0.017833467572927475, -0.05491018295288086, -0.052641112357378006, -0.010459048673510551, -0.052016086876392365, 0.020891955122351646, -0.07997036725282669, -0.012111340649425983, -0.05773142725229263, 0.023178234696388245, -0.008031732402741909, -0.02598930336534977, -0.07995671033859253, -0.020728832110762596, 0.048817697912454605, -0.020389137789607048, -0.04917657747864723, 0.014159622602164745, -0.06362202018499374, -0.007807393092662096, 0.01643155701458454, -0.0256824791431427, 0.013381040655076504, 0.026248741894960403, 0.009978413581848145, 0.06322886794805527, 0.002672201255336404, -0.006582767236977816, 0.01663188263773918, 0.03236646577715874, 0.03794245794415474, -0.036376070231199265, -0.006910930387675762, 0.0001596928050275892, -0.0016335808904841542, -0.02727821283042431, -0.02803807333111763, 0.049681417644023895, -0.028867173939943314, -0.0024180689360946417, 0.014774908311665058, 0.009764534421265125, 0.005797638092190027, 0.013486160896718502, 0.0055678957141935825, 0.03722710534930229, 0.007232527248561382, 0.04015626385807991, 0.08150326460599899, 0.07199167460203171, -0.013056126423180103, -0.0428820475935936, -0.01101123820990324, 0.004897820297628641, -0.009229730814695358, 0.035191506147384644, -0.05103502422571182, -1.571437557856825e-08, -0.08862441033124924, 0.02390925958752632, -0.01623876392841339, 0.031700510531663895, 0.027284247800707817, 0.05246882885694504, -0.047070957720279694, -0.058847445994615555, -0.06320822983980179, 0.04088849574327469, 0.04982800409197807, 0.10655171424150467, -0.07450230419635773, -0.012495421804487705, 0.01837071217596531, 0.03947412595152855, -0.024797886610031128, 0.014516262337565422, -0.03706921637058258, 0.02001572772860527, -4.85817035951186e-05, 0.00986657664179802, 0.024838753044605255, -0.05245814099907875, 0.029314178973436356, -0.08719190955162048, -0.01449968758970499, 0.026019077748060226, -0.01874636672437191, -0.07620512694120407, 0.03504333272576332, 0.10363949835300446, -0.028050510212779045, 0.012718182988464832, -0.07632549107074738, -0.01865232177078724, 0.02497672848403454, 0.0814453512430191, 0.06875883787870407, -0.0640566498041153, -0.08389385789632797, 0.06136231869459152, -0.033545564860105515, -0.10615336894989014, -0.040080588310956955, 0.032530225813388824, 0.07662483304738998, -0.0730162113904953, 0.00033755265758372843, -0.040871646255254745, -0.0757884755730629, 0.027527665719389915, 0.07462543249130249, 0.01771726831793785, 0.09121846407651901, 0.11022016406059265, 0.0005697731394320726, 0.05146336182951927, -0.014551310800015926, 0.03323203697800636, 0.023792240768671036, -0.02288980595767498, 0.038937538862228394, 0.030206844210624695]\n"
     ]
    }
   ],
   "source": [
    "emb = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "print(emb.embed_query(\"Hello World\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03f0c7",
   "metadata": {},
   "source": [
    "## Part 1: Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f62422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INDEXING ###\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=['https://lilianweng.github.io/posts/2023-06-23-agent/'],\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.filter.SoupStrainer(\n",
    "            class_=('post-content', 'post-title', 'post-header')\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396522de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "for i, doc in enumerate(splits):\n",
    "    if not doc.page_content.strip():\n",
    "        print(f\"Empty chunk at index {i} : {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b539019",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    [doc for doc in splits if doc.page_content.strip()],\n",
    "    HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bdfcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is the process of breaking down a complex task into smaller, manageable subtasks. It can be achieved through various methods, including simple prompting, task-specific instructions, and human inputs. This process helps agents plan ahead and understand the steps involved in completing a task.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### RETRIEVAL and GENERATION ###\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "# LLM\n",
    "# llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0)\n",
    "llm = ChatGroq(\n",
    "    model='llama-3.1-8b-instant',\n",
    "    api_key=groq_api_key,\n",
    "    temperature=0.0,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs, 'question': RunnablePassthrough()} | prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "rag_chain.invoke('What is Task Decomposition?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29dba95",
   "metadata": {},
   "source": [
    "## Part 2: Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05dda8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "question = \"What kinds of pets do I like?\"\n",
    "document = \"My favorite pet is a dog.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7473f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(question, 'cl100k_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca21bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd4b4a1c4f6459aa38e297707db32dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\Projects\\LangChain Tutorials\\learn\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d22dc22602403b90b4d9dbdbb02006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece351ec54074d0e9d13e4d437789cb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423d443f2c734ae3ad1c2f312ab8116a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c3cfb38a114d679a9af4db5e6ad93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4e6b48500a4cada9319ea74d2b6282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fd14926d194029b9a153369a4e3895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ab5e3d7f4c4eb986db40f252fd5771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551ae708f17540f19be2729aec80b8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f62b3b02c6417f8a15536cc64192c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1aab5ec43c448d5824f14ed69c24db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = HuggingFaceEmbeddings()\n",
    "query_result = embed.embed_query(question)\n",
    "document_result = embed.embed_query(document)\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bc1267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5686721731463987\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c38aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INDEXING ###\n",
    "\n",
    "# Load blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=['https://lilianweng.github.io/posts/2023-06-23-agent/'],\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.filter.SoupStrainer(\n",
    "            class_=('post-content', 'post-title', 'post-header')\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58899671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    splits,\n",
    "    HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2cabb0",
   "metadata": {},
   "source": [
    "## Part 3: Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd89d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3797c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_1044\\4059233835.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"What is Task Decomposition?\")\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b3e989e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7293de",
   "metadata": {},
   "source": [
    "## Part 4: Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88b62c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompts\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6d80eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Task Decomposition is the process of breaking down a complicated task into smaller and simpler steps that an agent can plan ahead and manage. It involves transforming big tasks into multiple manageable tasks, allowing for a clearer understanding of the thinking process involved.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 343, 'total_tokens': 391, 'completion_time': 0.09256295, 'prompt_time': 0.028858977, 'queue_time': 0.431566889, 'total_time': 0.121421927}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_46fc01befd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2f983bf4-a31a-43cc-a3c9-5e4a09b21846-0', usage_metadata={'input_tokens': 343, 'output_tokens': 48, 'total_tokens': 391})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatGroq(model='llama-3.1-8b-instant', temperature=0)\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run\n",
    "chain.invoke({'context':docs, \"question\":\"What is Task Decomposition?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a2add4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt_hub_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "260fd189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is the process of breaking down a complicated task into smaller and simpler steps that an agent can plan ahead and manage. It involves transforming big tasks into multiple manageable tasks, allowing for a clearer understanding of the thinking process involved.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\":retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
