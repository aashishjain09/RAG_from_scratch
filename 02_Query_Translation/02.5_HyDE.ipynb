{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7c83f0",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a243456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4, tiktoken, numpy as np, os\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "learn_api_key = os.environ['LANGCHAIN_API_KEY']\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9611785",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INDEXING ###\n",
    "loader = WebBaseLoader(\n",
    "    web_path=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300, chunk_overlap=50)\n",
    "\n",
    "# Make Splits\n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# Index\n",
    "vectorstore = Chroma.from_documents(\n",
    "    splits,\n",
    "    HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d914d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## Task Decomposition for Large Language Model Agents: Breaking Down Complexity for Effective Action\\n\\nLarge Language Model (LLM) agents, while demonstrating impressive capabilities, often struggle with complex tasks requiring multiple sequential steps or diverse sub-tasks. This limitation stems from their inherent nature as text-based models, lacking the explicit reasoning and planning mechanisms found in traditional AI agents. To address this, **task decomposition** emerges as a crucial technique, enabling LLMs to tackle complex tasks by breaking them down into smaller, more manageable sub-tasks.\\n\\nTask decomposition involves identifying the constituent sub-tasks within a larger goal and formulating them as individual, well-defined problems. This process can be achieved through various methods, including:\\n\\n* **Rule-based decomposition:** Utilizing predefined rules or templates to identify recurring patterns and decompose tasks accordingly.\\n* **Hierarchical decomposition:** Breaking down tasks into a hierarchy of sub-tasks, with each level representing a progressively finer granularity of action.\\n* **Graph-based decomposition:** Representing tasks as graphs, where nodes represent sub-tasks and edges represent dependencies between them.\\n\\nBy decomposing complex tasks, LLMs can leverage their strengths in natural language understanding and generation to solve each sub-task individually. This modular approach offers several advantages:\\n\\n* **Improved performance:** Breaking down complex problems into smaller, more manageable chunks allows LLMs to focus their resources and achieve higher accuracy.\\n* **Enhanced robustness:** Decomposing tasks reduces the impact of errors in individual sub-tasks, as the overall performance is not solely dependent on the success of a single step.\\n* **Increased flexibility:** Task decomposition allows for the reuse of pre-trained sub-task modules, enabling LLMs to adapt to new tasks with minimal modifications.\\n\\nFurthermore, task decomposition facilitates the integration of external tools and knowledge sources. Each sub-task can be tailored to leverage specific tools or data, enabling LLMs to perform more sophisticated and specialized actions.\\n\\nIn conclusion, task decomposition is a vital technique for empowering LLM agents to effectively handle complex tasks. By breaking down problems into smaller, manageable units, LLMs can leverage their strengths, improve performance, and achieve greater flexibility in tackling real-world challenges.\\n\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HyDE document generation\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatGroq(model='openai/gpt-oss-20b', api_key=groq_api_key, temperature=0)\n",
    "\n",
    "generate_docs_for_retrieval = (prompt_hyde | ChatGroq(model=\"gemma2-9b-it\", api_key=groq_api_key, temperature=0) | StrOutputParser())\n",
    "\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_docs_for_retrieval.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67dad242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Or\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "retrieval_chain = generate_docs_for_retrieval | retriever\n",
    "retrieved_docs = retrieval_chain.invoke({\"question\":question})\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c32d72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Task decomposition for LLM agents** is the process by which an autonomous agent powered by a large language model (LLM) splits a complex, high‑level goal into a sequence of smaller, more manageable sub‑tasks or sub‑goals. This decomposition is essential for the agent to:\\n\\n1. **Make the problem tractable** – By breaking a big problem into bite‑size pieces, the agent can reason about each piece individually, which is far easier than tackling the whole problem at once.  \\n2. **Plan and execute** – Each sub‑goal can be turned into a concrete plan (e.g., a list of steps or API calls) that the agent can follow.  \\n3. **Reflect and refine** – After executing a sub‑goal, the agent can evaluate its success, learn from mistakes, and adjust subsequent sub‑goals accordingly.\\n\\n### How it’s done\\n\\n| Method | How it works | Typical prompt |\\n|-------|-------------|---------------|\\n| **LLM‑driven prompting** | The LLM itself is asked to enumerate the steps needed to achieve the overall goal. | “Steps for XYZ. 1.” or “What are the subgoals for achieving XYZ?” |\\n| **Task‑specific instructions** | The prompt is tailored to the domain (e.g., “Write a story outline.”). | “Write a story outline.” |\\n| **Human‑guided decomposition** | A human provides the sub‑goals or refines the LLM’s output. | – |\\n\\n### Related techniques\\n\\n- **Chain of Thought (CoT)** – The LLM is instructed to “think step by step,” turning a hard task into a sequence of simpler reasoning steps.  \\n- **Tree of Thoughts (ToT)** – Extends CoT by generating multiple possible thoughts at each step, forming a tree that can be searched (BFS/DFS) to find the best path.\\n\\n### Why it matters\\n\\n- **Finite context**: LLMs have limited context windows, so breaking tasks into smaller chunks keeps each step within the model’s memory.  \\n- **Robustness**: Decomposing tasks allows the agent to recover from errors by revisiting or re‑planning sub‑goals.  \\n- **Reliability**: Clear sub‑goals reduce the chance of formatting or “rebellious” behavior from the LLM.\\n\\n> *“Task decomposition can be done (1) by LLM with simple prompting… (2) by using task‑specific instructions… (3) with human inputs.”* – Lilian Weng, *LLM‑powered Autonomous Agents* (2023).\\n\\nIn short, task decomposition is the foundational strategy that lets LLM agents tackle complex problems by breaking them into a chain (or tree) of smaller, solvable sub‑tasks.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (prompt | llm | StrOutputParser())\n",
    "\n",
    "final_rag_chain.invoke({\"context\":retrieved_docs, \"question\":question})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
