{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f236d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4, tiktoken, numpy as np, os, datetime\n",
    "from typing import Literal, Optional, Tuple\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain import hub\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader, YoutubeLoader\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "learn_api_key = os.environ['LANGSMITH_API_KEY']\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "groq_api_key = os.environ['GROQ_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d470967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "video_id = \"a8FTr2qMutA\"\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
    "docs = \" \".join([t[\"text\"] for t in transcript])\n",
    "print(docs[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f706cb1",
   "metadata": {},
   "source": [
    "## Part 1: Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INDEXING ###\n",
    "\n",
    "# Load Documents\n",
    "video_id = \"Ks-_Mh1QhMc\"\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "docs = \" \".join([t[\"text\"] for t in transcript])\n",
    "docs[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TutorialSearch(BaseModel):\n",
    "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
    "    content_search: str = Field(\n",
    "        ...,\n",
    "        description=\"Similarity search query applied to video transcripts.\"\n",
    "    )\n",
    "    title_search: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "        \"Alternate version of the content search query to apply to video titles. \"\n",
    "        \"Should be succint and only include key words that could be in a video title.\"\n",
    "        ),\n",
    "    )\n",
    "    min_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum view count filter, inclusive. Only use if explicitly specified.\"\n",
    "    )\n",
    "    max_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum view count filter, exclusive. Only use if explicitly specified.\"\n",
    "    )\n",
    "    earliest_publish_date: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Earliest publish date filter, inclusive. Only use if explicitly specified.\"\n",
    "    )\n",
    "    latest_publish_date: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Latest publish date filter, exclusive. Only use if explicitly specified.\"\n",
    "    )\n",
    "    min_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum video length in seconds, inclusive. Only use if explicitly specified.\"\n",
    "    )\n",
    "    max_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum video length in seconds, exclusive. Only use if explicitly specified.\"\n",
    "    )\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field in TutorialSearch.model_fields:\n",
    "            if getattr(self, field) is not None and getattr(self, field) != getattr(TutorialSearch.model_fields[field], \"default\", None):\n",
    "                print(f\"{field}: {getattr(self, field)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3264d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "    You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "    Given a question, return a database query optimized to retrieve the most relevant results.\n",
    "    \n",
    "    If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\", api_key=groq_api_key, temperature=0)\n",
    "structured_llm = llm.with_structured_output(TutorialSearch)\n",
    "query_analyzer = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba9321",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_analyzer.invoke({\"question\":\"rag from scratch\"}).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"videos on chat langchain published in 2023\"}\n",
    ").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c572914",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"videos that are focused on the topic of chat langchain that are published before 2024\"}\n",
    ").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be542fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"how to use mutli-modal models in an agent, only videos under 5 minutes\"}\n",
    ").pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
